{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Behavioral Cloning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Behavioral Cloning Project**\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "* Use the simulator to collect data of good driving behavior\n",
    "* Build, a convolution neural network in Keras that predicts steering angles from images\n",
    "* Train and validate the model with a training and validation set\n",
    "* Test that the model successfully drives around track one without leaving the road\n",
    "* Summarize the results with a written report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training Data**\n",
    "\n",
    "Training data was chosen to keep the vehicle driving on the road. The input data to the model are camara images and steering angle. There are three camera images: left, center and right\n",
    "<table><tr>\n",
    "<td><figure>\n",
    "    <img  src=\"./report_images/left.jpg\" alt=\"Drawing\" style=\"width: 350px;\"/>\n",
    "    <figcaption>Left</figcaption>\n",
    "    </figure></td>\n",
    "<td><figure>\n",
    "    <img  src=\"./report_images/center.jpg\" alt=\"Drawing\" style=\"width: 350px;\"/>\n",
    "    <figcaption>Center</figcaption>\n",
    "    </figure></td>\n",
    "<td><figure>\n",
    "    <img  src=\"./report_images/right.jpg\" alt=\"Drawing\" style=\"width: 350px;\"/>\n",
    "    <figcaption>Right</figcaption>\n",
    "    </figure></td>    \n",
    "</tr></table>\n",
    "\n",
    "----\n",
    "The file paths for those images are stored in .csv file together with steering angle values\n",
    "<figure>\n",
    "    <figcaption>Input data</figcaption>\n",
    "    <img  src=\"./report_images/csv_data.jpg\" alt=\"Drawing\" style=\"width: 800px;\"/>\n",
    "</figure>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture and Training Strategy\n",
    "\n",
    "#### 1. Solution Design Approach\n",
    "The first step is image preprocessing:\n",
    "* Normalization\n",
    "* Image cropping\n",
    "\n",
    "**Normalization**\n",
    "```python\n",
    "model.add(Lambda(lambda x: x/255.0 - 0.5,input_shape=(160,320,3)))\n",
    "```\n",
    "**Image cropping**\n",
    "The reason for this step is that, for each camera image, the top half shows sky or tree, which could be noise for model training. To make training easier, the tree/sky and front part of vechile are cropped away, the following figures give some examples:\n",
    "\n",
    "<table><tr>\n",
    "<td><figure>\n",
    "    <img  src=\"./report_images/left_cropped.jpg\" alt=\"Drawing\" style=\"width: 350px;\"/>\n",
    "    <figcaption>Left</figcaption>\n",
    "    </figure></td>\n",
    "<td><figure>\n",
    "    <img  src=\"./report_images/center_cropped.jpg\" alt=\"Drawing\" style=\"width: 350px;\"/>\n",
    "    <figcaption>Center</figcaption>\n",
    "    </figure></td>\n",
    "<td><figure>\n",
    "    <img  src=\"./report_images/right_cropped.jpg\" alt=\"Drawing\" style=\"width: 350px;\"/>\n",
    "    <figcaption>Right</figcaption>\n",
    "    </figure></td>    \n",
    "</tr></table>\n",
    "\n",
    "The first network used is `Lenet` convolution neural netowrk. The model showed controlling steering to keep vehicle to the center of the road. But couldn't go to far. \n",
    "In order to improve the overall model performance, two data augmentation schemes are done\"\n",
    "* Using all three camera images\n",
    "* Flip all the images\n",
    "\n",
    "**Using all three camera images**\n",
    "\n",
    "```python\n",
    "                for i in range(3):\n",
    "                    source_path = line[i]\n",
    "                    filename = source_path.split('/')[-1]\n",
    "                    current_path = './data/IMG/' + filename\n",
    "                    image = cv2.imread(current_path)\n",
    "                    batch_images.append(image)\n",
    "                    angle = steering_center\n",
    "                    if i==1: #if data from left camera add correction\n",
    "                        angle +=correction\n",
    "                    if i==2: #if data from right camera add minus correction\n",
    "                        angle -=correction\n",
    "```\n",
    "For left camera image, the steering angle is set to 0.25, and -0.25 for images from the right camera\n",
    "\n",
    "**Flip all the images**\n",
    "```python\n",
    "                    batch_angles.append(angle)\n",
    "                    #flip image to augment data\n",
    "                    batch_images.append(cv2.flip(image,1))\n",
    "                    batch_angles.append(angle*(-1.0))\n",
    "```\n",
    "When an images is flipped, its angle should be inversed\n",
    "\n",
    "After image augmentation, the Lenet model performance showed some improvement\n",
    "\n",
    "**Overfitting**\n",
    "To avoid overfitting, dropout layers are inserted in between fully connected layers\"\n",
    "```python\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(50))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(1))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The final model is shown below**\n",
    "```\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "lambda_2 (Lambda)            (None, 160, 320, 3)       0         \n",
    "_________________________________________________________________\n",
    "cropping2d_2 (Cropping2D)    (None, 65, 320, 3)        0         \n",
    "_________________________________________________________________\n",
    "conv2d_6 (Conv2D)            (None, 31, 158, 24)       1824      \n",
    "_________________________________________________________________\n",
    "conv2d_7 (Conv2D)            (None, 14, 77, 36)        21636     \n",
    "_________________________________________________________________\n",
    "conv2d_8 (Conv2D)            (None, 5, 37, 48)         43248     \n",
    "_________________________________________________________________\n",
    "conv2d_9 (Conv2D)            (None, 3, 35, 64)         27712     \n",
    "_________________________________________________________________\n",
    "conv2d_10 (Conv2D)           (None, 1, 33, 64)         36928     \n",
    "_________________________________________________________________\n",
    "flatten_2 (Flatten)          (None, 2112)              0         \n",
    "_________________________________________________________________\n",
    "dense_5 (Dense)              (None, 100)               211300    \n",
    "_________________________________________________________________\n",
    "dropout_3 (Dropout)          (None, 100)               0         \n",
    "_________________________________________________________________\n",
    "dense_6 (Dense)              (None, 50)                5050      \n",
    "_________________________________________________________________\n",
    "dropout_4 (Dropout)          (None, 50)                0         \n",
    "_________________________________________________________________\n",
    "dense_7 (Dense)              (None, 10)                510       \n",
    "_________________________________________________________________\n",
    "dense_8 (Dense)              (None, 1)                 11        \n",
    "=================================================================\n",
    "Total params: 348,219\n",
    "Trainable params: 348,219\n",
    "Non-trainable params: 0\n",
    "\n",
    "```\n",
    "\n",
    "With this final model, the vehicle is able to drive autonomously around the track without leaving the road."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
